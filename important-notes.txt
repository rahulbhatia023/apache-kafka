Approaches to send a message to kafka
=====================================

Fire-and-forget Producer
------------------------
Send and forget is the simplest approach. In this method, we send a message to the broker and donâ€™t care if it was successfully received or not.
You might be wondering that is this a right approach? Where to use that method?
Well, Kafka is a distributed system. It comes with inbuilt fault tolerance feature. That makes Kafka a highly available system.
So most of the time, your message will reach to the broker. We also know that producer will automatically retry in case of recoverable error.
So, the probability of losing your messages is thin.
There are many use cases where you are dealing with huge volumes and losing a small portion of records is not critical.
For example, if you are counting hits on a video, or collecting a twitter feed for sentiment analysis. In such use cases,
even if you lose 2-3% of your tweets, it may not be a problem.
But, it is important to understand that in fire and forget approach, you may lose some messages.
So, don't use this method when you can't afford to lose your messages.

Synchronous Producer
--------------------
In this approach, we send a message and wait until we get a response.
In the case of a success, we get a RecordMetadata object, and in the event of failure, we get an exception.
Most of the time, we don't care about the success and the RecordMetadata that we receive.
We only care about exception because we want to log errors for later analysis and appropriate action.
You can adopt this method if your messages are critical and you can't afford to lose anything.
But it is important to notice that synchronous approach will slow you down.
It will limit your throughput because you are waiting for every message to get acknowledged.
You are sending one message and waiting for success, then you send your next message, and again wait for success.
Each message will take some time to be delivered over the network.
So, after every message, you will be waiting for a network delay.
And the most interesting thing is that, you may not be doing anything in case of success.
You care only failures, if it fails, you may want to take some action.
The fire and forget approach was on one extreme, and the synchronous approach is at another extreme.
I mean, in one approach, you don't care at all, and in another method, you wait for every single message.
So, there is a third approach which takes the middle path.

Asynchronous Producer
---------------------
In this method, we send a message and provide a call back function to receive acknowledgment.
We don't wait for success and failure. The producer will callback our function with RecordMetadata and an exception object.
So, if you just care about exceptions, you simply look at the exception, if it is null, don't do anything.
If the exception is not null, then you know it failed, so you can record the message details for later analysis.
In this approach, you keep sending messages as fast as you can without waiting for responses,
and handle failures later as they come using a callback function.
The asynchronous method appears to provide you a throughput that is as good as fire and forget approach.
But there is a catch. You have a limit of in-flight messages.
This limit is controlled by a configuration parameter max.in.flight.requests.per.connection.
This parameter controls that how many messages you can send to the server without receiving a response. The default value is 5.
You can increase this value, but there are other considerations.
Asynchronous send gives you a better throughput compared to synchronous, but the max.in.flight.requests.per.connection limits it.

There is a side effect of asynchronous send. Let's assume you send 10 requests for same partition.
5 of them were sent as the first batch and failed. Remaining five goes as a second batch and succeed.
Now the producer will retry the first batch, and if it is successful, you lost your order.
That's a significant side effect of asynchronous send. So, be careful if the order of delivery is critical for you.
If you are looking for an ordered delivery of your messages, you have following two options.

Use synchronous send.
set max.in.flight.requests.per.connection to 1

Both options have the same result. The order is critical for some use cases, especially transactional systems, for example banks and inventory.
If you are working on that kind of use case, set max.in.flight.requests.per.connection to 1.


Problems with Kafka Custom Serializer/Deserializer
==================================================
The problem with this approach is managing future changes in the schema.
Suppose you implemented this serializer and deserializer, and your system is functional for few months.
After few months, you have a requirement to add another field in the supplier object.
If you modify your Supplier object, you must change your serializer and deserializer, may be the producer and consumer as well.
But the problem doesn't end there.
After making new changes, you can't read your older messages because you changed the format and modified your code to read the new format.
That's where generic serializers like Avro will be helpful.


Kafka Producer Configs
======================

acks
----
The acks configuration is to configure acknowledgments.
When producers send a message to Kafka broker, they get a response back from the broker.
The response is a RecordMetaData object or an exception.
This parameter acks, it can take three values: 0, 1, and all.

acks=0 : the producer will not wait for the response. It will send the message over the network and forget.
There are side effects of acks being 0:
Possible loss of messages
No Retries

acks=1: the producer will wait for the response. However, the response is sent by the leader.
In this case, the leader will respond after recording the message in its local storage.
If the leader is down and message delivery fails, the producer can retry after few milliseconds.
This option appears to be a safe choice. You still cannot guarantee that you will not lose your message.
We are not sure that it is replicated.
If the leader breaks before replica could make a copy, the message will be lost.
Surprisingly, in such scenario, the messages can be lost even after successful acknowledgment.
If you want to achieve 100% reliability, it is necessary that all replicas in the ISR list should make a copy successfully
before the leader sends an acknowledgment.

acks=all: If we set acks parameter to all, the leader will acknowledge only after it receives an acknowledgment from all of the live replicas.
This option gives you the highest reliability but costs you the highest latency.

retries
-------
It defines how many times the producer will retry after getting an error. The default value is 0.
There is another parameter 'retry.backoff.ms' that controls the time between two retries. The default value for this parameter is 100 milliseconds.


Kafka Consumer Groups
=====================

If your producers are pushing data to the topic at a moderate speed, a single consumer may be enough to read and process that data.
However, if you want to scale up your system and read data from Kafka in parallel, you need multiple consumers reading your topic in parallel.
Many applications may have a clear need for multiple producers pushing data to a topic at one end and multiple consumers reading and processing data on the other end.
There is no complexity at the producer side. It is as simple as executing another instance of a producer.
There is no coordination or sharing of information needed among producers.
But on the consumer side, we have various considerations.

When I talk about parallel reading, I am speaking about one single application consuming data in parallel.
It is not about multiple applications reading same Kafka topic in parallel.
So, the question is, how to implement parallel reads in a single application.
We can do that by creating a group and starting multiple consumers in the same group.

If we have multiple consumers reading data in parallel from the same topic, don't you think that all of them can read the same message?
The answer is no. Only one consumer owns a partition at any point in time.

Let's take an example to understand this.
We have one topic, and there are four partitions. So, if we have only one consumer in a group, it reads from all four partitions.
If you have two, each of them reads two partitions.
If you have three, the arrangement may be something like a single consumer reading two partitions and others own a single partition each.
So, the fundamental concept is that the consumers do not share a partition. There is no way we can read the same message more than once.
However, this solution also brings a limitation. The number of partitions on a topic is the upper limit of consumers you can have in a group.
So, in our example, if you have five consumers, one of them reads nothing.
Kafka won't complain that you have four partitions, but you are starting five consumers. Simply, the fifth consumer will have nothing to read.

How does a consumer enter and exit into a group?
-----------------------------------------------
Question is, how Kafka handles it?
When a consumer joins a group, how is a partition assigned to it?
Moreover, what happens to the partition when a consumer leaves the group? Who manages all of this?

Kafka Group Coordinator
-----------------------
A group coordinator oversees all of this. So, one of the Kafka broker gets elected as a Group Coordinator.
When a consumer wants to join a group, it sends a request to the coordinator. The first consumer to participate in a group becomes a leader.
All other consumers joining later becomes the members of the group.
So, we have two actors, A coordinator, and a group leader. The coordinator is responsible for managing a list of group members.
So, every time a new member joins the group, or an existing member leaves the group, the coordinator modifies the list.
On an event of membership change, the coordinator realizes that it is time to rebalance the partition assignment.
Because you may have a new member, and you need to assign it some partitions, or a member left, and you need to reassign those partitions to someone else.
So, every time the list is modified, the coordinator initiates a rebalance activity.

Kafka Group Leader
------------------
The group leader is responsible for executing rebalance activity.
The group leader will take a list of current members, assign partitions to them and send it back to the coordinator.
The Coordinator then communicates back to the members about their new partitions.
The important thing to note here is, during the rebalance activity, none of the consumers are allowed to read any message.


Kafka Consumer: The Poll Method
===============================
The poll function is pretty powerful and takes care of a lot of things.
It handles all the coordination, partition rebalances, and heart beat for group coordinator.
When you call to poll for the first time from a consumer, it finds a group coordinator, joins the group, receives partition assignment
and fetches some records from those partitions.
Every time you call to poll, it will send a heartbeat to group coordinator.
So, it is necessary that whatever you do in a consumer, it should be quick and efficient.
If you don't poll for a while, the coordinator may assume that the consumer is dead and trigger a partition rebalance.


Offset Management
=================

The offset is a position within a partition for the next message to be sent to a consumer. Kafka maintains two types of offsets:

Current offset
Committed offset

Current Offset
--------------
When we call a poll method, Kafka sends some messages to us. Let us assume we have 100 records in the partition.
The initial position of the current offset is 0. We made our first call and received 20 messages. Now Kafka will move the current offset to 20.
When we make our next request, it will send some more messages starting from 20 and again move the current offset forward.
The offset is a simple integer number that is used by Kafka to maintain the current position of a consumer.
The current offset is a pointer to the last record that Kafka has already sent to a consumer in the most recent poll.

Committed Offset
----------------
It is the position that a consumer has confirmed about processing. What does that mean?
After receiving a list of messages, we want to process it. This processing may be just storing them into HDFS.
Once we are sure that we have successfully processed the record, we may want to commit the offset.
So, the committed offset is a pointer to the last record that a consumer has successfully processed.
For example, the consumer received 20 records. It is processing them one by one, and after processing each record, it is committing the offset.

Current offset -> Sent Records -> This is used to avoid resending same records again to the same consumer.
Committed offset -> Processed Records -> It is used to avoid resending same records to a new consumer in the event of partition rebalance.

The committed offset is critical in the case of partition rebalance.
In the event of rebalancing. When a new consumer is assigned a new partition, it should ask a question.
Where to start? What is already processed by the previous owner? The answer to the question is the committed offset.

How to commit an offset?
-----------------------
There are two ways to do it.

Auto commit
Manual commit

Auto Commit
-----------
Auto-commit is the easiest method. You can control this feature by setting two properties:

enable.auto.commit
auto.commit.interval.ms

The first property is by default true. So auto-commit is enabled by default. You can turn it off by setting 'enable.auto.commit' to false.
The second property defines the interval of auto-commit. The default value for this property is 5 seconds.
So, in a default configuration, when you make a call to the poll method, it will check if it is time to commit.
If you have passed five seconds since the previous call, the consumer will commit the last offset.
So, Kafka will commit your offset every five seconds.
The auto-commit is a convenient option, but it may cause second processing of records. Let us understand it with an example.
You have some messages in the partition, and you made your first poll request.
You received 10 messages hence the consumer increases the current offset to 10.
You take four seconds to process these ten messages and make a new call. Since you haven't passed five seconds, the consumer will not commit the offset.
You received another set of records, and for some reason rebalance is triggered at this moment.
First ten records are already processed, but nothing is committed yet. Right? The rebalance is triggered.
So, the partition goes to a different consumer.
Since we don't have a committed offset, the new owner of partition should start reading from the beginning and process first ten records again.
You might be thinking that let's reduce the commit frequency to four seconds.
You can lower the incidence of commit by setting the auto-commit interval to a lower value, but you can't guarantee to eliminate repeat processing.

Manual Commit
-------------
We can configure the auto-commit off and manually commit after processing the records. There are two approaches to manual commit:

Commit Sync
Commit Async

Synchronous commit is a straightforward and reliable method, but it is a blocking method.
It will block your call for completing a commit operation, and it will also retry if there are recoverable errors.

Asynchronous commit will send the request and continue. The drawback is that async commit will not retry.
Let us assume that you are trying to commit an offset as 75. It failed for some recoverable reason, and you want to retry it after few seconds.
Since this was an asynchronous call, so without knowing that your previous commit is waiting, you initiated another commit.
This time it is to commit 100. Your commit 100 is successful while commit-75 waits for a retry.
What do you want to do? Obviously, you don't want to commit 75 after commit 100. That may cause problems.
So, they designed asynchronous commit to not to retry.
However, this behaviour is not an issue because you know that if one commit fails for a recoverable reason, the next higher order commit will succeed.


Rebalance Listener
==================
Suppose, we have a situation where we got a lot of data using the poll method, and it is going to take some reasonable time to complete the processing for all the records.
If you are taking a lot of time to process your records, you will have two types of risks:

1. The first risk is the delay in next poll, because you are busy processing data from the last call.
   If you don't poll for a long, the group coordinator might assume that you are dead and trigger a rebalance activity.
   You don't want that to happen, Right? Because you were not dead, you were computing.

2. The second risk is also related to rebalancing.
   The coordinator triggers a rebalance activity for some other reason while you are processing an extensive list of messages.

In both the cases, rebalance is triggered either because you didn't poll for a while or something else went wrong.
Your current partitions will be taken away from you and reassigned to some other consumer.
In such cases, you would want to commit whatever you have already processed before the ownership of the partition is taken away from you.
And the new owner of the partition is supposed to start consuming it from the last committed offset.

Kafka API allows us to specify a ConsumerRebalanceListener class. This class offers two methods:

onPartitionsRevoked() - The Kafka will call the onPartitionsRevoked method just before it takes away your partitions.
So, this is where you can commit your current offset.

onPartitionsAssigned() - The Kafka will call the onPartitionsAssigned method right after the rebalancing is complete and
before you start consuming records from the new partitions.