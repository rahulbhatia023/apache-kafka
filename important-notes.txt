Approaches to send a message to kafka
=====================================

Fire-and-forget Producer
------------------------
Send and forget is the simplest approach. In this method, we send a message to the broker and donâ€™t care if it was successfully received or not.
You might be wondering that is this a right approach? Where to use that method?
Well, Kafka is a distributed system. It comes with inbuilt fault tolerance feature. That makes Kafka a highly available system.
So most of the time, your message will reach to the broker. We also know that producer will automatically retry in case of recoverable error.
So, the probability of losing your messages is thin.
There are many use cases where you are dealing with huge volumes and losing a small portion of records is not critical.
For example, if you are counting hits on a video, or collecting a twitter feed for sentiment analysis. In such use cases,
even if you lose 2-3% of your tweets, it may not be a problem.
But, it is important to understand that in fire and forget approach, you may lose some messages.
So, don't use this method when you can't afford to lose your messages.

Synchronous Producer
--------------------
In this approach, we send a message and wait until we get a response.
In the case of a success, we get a RecordMetadata object, and in the event of failure, we get an exception.
Most of the time, we don't care about the success and the RecordMetadata that we receive.
We only care about exception because we want to log errors for later analysis and appropriate action.
You can adopt this method if your messages are critical and you can't afford to lose anything.
But it is important to notice that synchronous approach will slow you down.
It will limit your throughput because you are waiting for every message to get acknowledged.
You are sending one message and waiting for success, then you send your next message, and again wait for success.
Each message will take some time to be delivered over the network.
So, after every message, you will be waiting for a network delay.
And the most interesting thing is that, you may not be doing anything in case of success.
You care only failures, if it fails, you may want to take some action.
The fire and forget approach was on one extreme, and the synchronous approach is at another extreme.
I mean, in one approach, you don't care at all, and in another method, you wait for every single message.
So, there is a third approach which takes the middle path.

Asynchronous Producer
---------------------
In this method, we send a message and provide a call back function to receive acknowledgment.
We don't wait for success and failure. The producer will callback our function with RecordMetadata and an exception object.
So, if you just care about exceptions, you simply look at the exception, if it is null, don't do anything.
If the exception is not null, then you know it failed, so you can record the message details for later analysis.
In this approach, you keep sending messages as fast as you can without waiting for responses,
and handle failures later as they come using a callback function.
The asynchronous method appears to provide you a throughput that is as good as fire and forget approach.
But there is a catch. You have a limit of in-flight messages.
This limit is controlled by a configuration parameter max.in.flight.requests.per.connection.
This parameter controls that how many messages you can send to the server without receiving a response. The default value is 5.
You can increase this value, but there are other considerations.
Asynchronous send gives you a better throughput compared to synchronous, but the max.in.flight.requests.per.connection limits it.

There is a side effect of asynchronous send. Let's assume you send 10 requests for same partition.
5 of them were sent as the first batch and failed. Remaining five goes as a second batch and succeed.
Now the producer will retry the first batch, and if it is successful, you lost your order.
That's a significant side effect of asynchronous send. So, be careful if the order of delivery is critical for you.
If you are looking for an ordered delivery of your messages, you have following two options.

Use synchronous send.
set max.in.flight.requests.per.connection to 1

Both options have the same result. The order is critical for some use cases, especially transactional systems, for example banks and inventory.
If you are working on that kind of use case, set max.in.flight.requests.per.connection to 1.


Problems with Kafka Custom Serializer/Deserializer
==================================================
The problem with this approach is managing future changes in the schema.
Suppose you implemented this serializer and deserializer, and your system is functional for few months.
After few months, you have a requirement to add another field in the supplier object.
If you modify your Supplier object, you must change your serializer and deserializer, may be the producer and consumer as well.
But the problem doesn't end there.
After making new changes, you can't read your older messages because you changed the format and modified your code to read the new format.
That's where generic serializers like Avro will be helpful.


Kafka Producer Configs
======================

acks
----
The acks configuration is to configure acknowledgments.
When producers send a message to Kafka broker, they get a response back from the broker.
The response is a RecordMetaData object or an exception.
This parameter acks, it can take three values: 0, 1, and all.

acks=0 : the producer will not wait for the response. It will send the message over the network and forget.
There are side effects of acks being 0:
Possible loss of messages
No Retries

acks=1: the producer will wait for the response. However, the response is sent by the leader.
In this case, the leader will respond after recording the message in its local storage.
If the leader is down and message delivery fails, the producer can retry after few milliseconds.
This option appears to be a safe choice. You still cannot guarantee that you will not lose your message.
We are not sure that it is replicated.
If the leader breaks before replica could make a copy, the message will be lost.
Surprisingly, in such scenario, the messages can be lost even after successful acknowledgment.
If you want to achieve 100% reliability, it is necessary that all replicas in the ISR list should make a copy successfully
before the leader sends an acknowledgment.

acks=all: If we set acks parameter to all, the leader will acknowledge only after it receives an acknowledgment from all of the live replicas.
This option gives you the highest reliability but costs you the highest latency.

retries
-------
It defines how many times the producer will retry after getting an error. The default value is 0.
There is another parameter 'retry.backoff.ms' that controls the time between two retries. The default value for this parameter is 100 milliseconds.